{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a29a5a0b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import sklearn as sklearn\n",
    "import numpy as np\n",
    "import time\n",
    "import scipy\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import lightgbm as lg\n",
    "import optuna\n",
    "import optuna.integration.lightgbm as lgb\n",
    "import xgboost as xgb\n",
    "import pickle\n",
    "import os\n",
    "from datetime import date\n",
    "\n",
    "from typing import List, TypeVar, Dict\n",
    "import abc\n",
    "\n",
    "from sklearn.pipeline import Pipeline\n",
    "from pandas.core.frame import DataFrame\n",
    "from sklearn.preprocessing import FunctionTransformer\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.neighbors import KNeighborsRegressor\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.preprocessing import minmax_scale\n",
    "from sklearn.preprocessing import MaxAbsScaler\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.preprocessing import RobustScaler\n",
    "from sklearn.preprocessing import Normalizer\n",
    "from sklearn.preprocessing import QuantileTransformer\n",
    "from sklearn.preprocessing import PowerTransformer\n",
    "from sklearn.model_selection import RepeatedKFold\n",
    "from sklearn.svm import LinearSVR\n",
    "from sklearn.svm import SVR\n",
    "from sklearn.metrics import mean_squared_error,roc_auc_score,precision_score\n",
    "from kydavra import FisherSelector\n",
    "\n",
    "from lightgbm import LGBMRegressor\n",
    "from catboost import CatBoostRegressor"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b5a98a9a",
   "metadata": {},
   "source": [
    "## Helper functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e78db6e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "_СORRELATION_MATRIX_PATH_ = 'corr_matrix.pcl'\n",
    "_СHURN_PATH_ = 'churn_model.pcl'\n",
    "_CHURN_PATH_REDUCED_ = 'churn_model_reduced.pcl' \n",
    "_MAX_FEATURES_ = 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "c1480700",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_float_cols(df:DataFrame) -> List[str]:\n",
    "    return df.select_dtypes(include=float).columns.tolist()\n",
    "\n",
    "def get_int_cols(df:DataFrame) -> List[str]:\n",
    "    return df.select_dtypes(include=int).columns.tolist()\n",
    "\n",
    "def get_number_cols(df:DataFrame) -> List[str]:\n",
    "    return df.select_dtypes(np.number).columns.tolist()\n",
    "\n",
    "def get_obj_cols(df:DataFrame) -> List[str]:\n",
    "    return list(df.select_dtypes(include=object).columns)\n",
    "\n",
    "def print_empty_values(df:DataFrame):\n",
    "    col_names_with_na = list(df.isna().sum()[lambda x: x > 0].index)\n",
    "    col_names_with_empty = list(df.isnull().sum()[lambda x: x > 0].index)\n",
    "    result = set(col_names_with_na) | set(col_names_with_empty)    \n",
    "    print('Columns with NA or empty: {0}'.format(result))\n",
    "    \n",
    "def get_empty_cols(df:DataFrame):\n",
    "    return list(df.isnull().sum()[lambda x: x > 0].index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "1207571b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def reduce_mem_usage(df, verbose=True) -> pd.DataFrame:\n",
    "    numerics = ['int16', 'int32', 'int64', 'float16', 'float32', 'float64']\n",
    "    start_mem = df.memory_usage().sum() / 1024**2    \n",
    "    for col in df.columns:\n",
    "        col_type = df[col].dtypes\n",
    "        if col_type in numerics:\n",
    "            c_min = df[col].min()\n",
    "            c_max = df[col].max()\n",
    "            if str(col_type)[:3] == 'int':\n",
    "                if c_min > np.iinfo(np.int8).min and c_max < np.iinfo(np.int8).max:\n",
    "                    df[col] = df[col].astype(np.int8)\n",
    "                elif c_min > np.iinfo(np.int16).min and c_max < np.iinfo(np.int16).max:\n",
    "                    df[col] = df[col].astype(np.int16)\n",
    "                elif c_min > np.iinfo(np.int32).min and c_max < np.iinfo(np.int32).max:\n",
    "                    df[col] = df[col].astype(np.int32)\n",
    "                elif c_min > np.iinfo(np.int64).min and c_max < np.iinfo(np.int64).max:\n",
    "                    df[col] = df[col].astype(np.int64)  \n",
    "            else:\n",
    "                if c_min > np.finfo(np.float16).min and c_max < np.finfo(np.float16).max:\n",
    "                    df[col] = df[col].astype(np.float16)\n",
    "                elif c_min > np.finfo(np.float32).min and c_max < np.finfo(np.float32).max:\n",
    "                    df[col] = df[col].astype(np.float32)\n",
    "                else:\n",
    "                    df[col] = df[col].astype(np.float64)    \n",
    "    end_mem = df.memory_usage().sum() / 1024**2\n",
    "    if verbose: print('Mem. usage decreased to {:5.2f} Mb ({:.1f}% reduction)'.format(end_mem, 100 * (start_mem - end_mem) / start_mem))\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "7e0ffcbc",
   "metadata": {},
   "outputs": [],
   "source": [
    "def split_test_train(df:DataFrame):\n",
    "    test, train = df[df['ind'].eq('test')], df[df['ind'].eq('train')]\n",
    "    test = test.drop(['ind'], axis=1)\n",
    "    train = train.drop(['ind'], axis=1)\n",
    "    return test, train\n",
    "    \n",
    "def combine_test_train(test:DataFrame, train:DataFrame):\n",
    "    combine = pd.concat([test.assign(ind='test'), train.assign(ind='train')])\n",
    "    target = train['target']\n",
    "    test_ids = test['Id']\n",
    "    return combine, target, test_ids\n",
    "\n",
    "def combine_data(train_df, train_num, train_dpi, test_df, test_num, test_dpi):\n",
    "    df_combine = pd.concat([train_df.assign(ind='train'), test_df.assign(ind='test')])\n",
    "    df_combine_num = pd.concat([train_num.assign(ind='train'), test_num.assign(ind='test')])\n",
    "    df_combine_dpi = pd.concat([train_dpi.assign(ind='train'), test_dpi.assign(ind='test')])\n",
    "    return df_combine, df_combine_num, df_combine_dpi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "2f25481a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def reduce_churn_data():\n",
    "\n",
    "    if os.path.exists(_CHURN_PATH_REDUCED_) == False:\n",
    "        if os.path.exists(_СHURN_PATH_) == True: \n",
    "    \n",
    "            with open(_СHURN_PATH_, 'rb') as file:\n",
    "                deserialized_object = pickle.load(file)\n",
    "\n",
    "            deserialized_object = list(deserialized_object)\n",
    "        \n",
    "            # reduce size\n",
    "            train_df= reduce_mem_usage(deserialized_object[1][1])\n",
    "            train_num_reduced = reduce_mem_usage(deserialized_object[1][2])\n",
    "            train_dpi_reduced = reduce_mem_usage(deserialized_object[1][3])\n",
    "\n",
    "            test_df = reduce_mem_usage(deserialized_object[2][1])\n",
    "            test_num_reduced = reduce_mem_usage(deserialized_object[2][2])\n",
    "            test_dpi_reduced = reduce_mem_usage(deserialized_object[2][3])\n",
    "            \n",
    "            # dump data back\n",
    "            deserialized_object = tuple([[train_df, train_num_reduced, train_dpi_reduced], [test_df, test_num_reduced, test_dpi_reduced]])\n",
    "            pickle.dump(deserialized_object, open(_CHURN_PATH_REDUCED_, 'wb'))\n",
    "    else:\n",
    "        print(f'{_CHURN_PATH_REDUCED_} already exist')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "7e6e18f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_churn_data():\n",
    "\n",
    "    with open(_СHURN_PATH_, 'rb') as file:\n",
    "        deserialized_object = pickle.load(file)\n",
    "\n",
    "    train_df = deserialized_object[1][1]\n",
    "    train_num = deserialized_object[1][2]\n",
    "    train_dpi = deserialized_object[1][3]\n",
    "\n",
    "    test_df = deserialized_object[2][1]\n",
    "    test_num = deserialized_object[2][2]\n",
    "    test_dpi = deserialized_object[2][3]\n",
    "\n",
    "    return train_df, train_num, train_dpi, test_df, test_num, test_dpi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "d952ad16",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_churn_reduced():\n",
    "\n",
    "    with open(_CHURN_PATH_REDUCED_, 'rb') as file:\n",
    "        deserialized_object = pickle.load(file)\n",
    "\n",
    "    train_df = deserialized_object[0][0]\n",
    "    train_num = deserialized_object[0][1]\n",
    "    train_dpi = deserialized_object[0][2]\n",
    "\n",
    "    test_df = deserialized_object[1][0]\n",
    "    test_num = deserialized_object[1][1]\n",
    "    test_dpi = deserialized_object[1][2]\n",
    "\n",
    "    return train_df, train_num, train_dpi, test_df, test_num, test_dpi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "f00265aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "def is_short_number(number:str) -> bool:\n",
    "    if (number.isdigit() and len(number) <= 4):\n",
    "        return True\n",
    "    return False\n",
    "\n",
    "def is_life(number:str) -> bool:\n",
    "    if (len(number) == 12 and (number[2:5] in ['063', '093' ])):\n",
    "        return True\n",
    "    return False\n",
    "\n",
    "def is_kyivstar(number:str) -> bool:\n",
    "    if (len(number) == 12 and (number[2:5] in ['067', '097', '068', '098'])):\n",
    "        return True\n",
    "    return False"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0ca85d64",
   "metadata": {},
   "source": [
    "### Feature selectors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "7024508e",
   "metadata": {},
   "outputs": [],
   "source": [
    "class FeatureHelper:\n",
    "    \n",
    "    def get_feature_correlation_df(corr_m, remove_duplicates=True, remove_self_correlations=True):\n",
    "    \n",
    "        corr_matrix_abs = corr_m.abs()\n",
    "        corr_matrix_abs_us = corr_matrix_abs.unstack()\n",
    "        sorted_correlated_features = corr_matrix_abs_us \\\n",
    "            .sort_values(kind=\"quicksort\", ascending=False) \\\n",
    "            .reset_index()\n",
    "\n",
    "        # Remove comparisons of the same feature\n",
    "        if remove_self_correlations:\n",
    "            sorted_correlated_features = sorted_correlated_features[\n",
    "                (sorted_correlated_features.level_0 != sorted_correlated_features.level_1)\n",
    "            ]\n",
    "\n",
    "        # Remove duplicates\n",
    "        if remove_duplicates:\n",
    "            sorted_correlated_features = sorted_correlated_features.iloc[:-2:2]\n",
    "\n",
    "        # Create meaningful names for the columns\n",
    "        sorted_correlated_features.columns = ['f1', 'f2', 'corr']\n",
    "\n",
    "        return sorted_correlated_features\n",
    "    \n",
    "    def get_correlation_matrix(df:DataFrame, method:str, save_path:str):\n",
    "        if os.path.exists(save_path) == False:\n",
    "            corr_matrix = df.corr(method = method, numeric_only = True)\n",
    "            pickle.dump(corr_matrix, open(save_path, 'wb'))\n",
    "        else:\n",
    "            corr_matrix = pickle.load(open(save_path, 'rb'))\n",
    "\n",
    "        return corr_matrix\n",
    "\n",
    "    def remove_aggr_function(str_to_check:str) -> str:\n",
    "        parts = str_to_check.split('_')\n",
    "        \n",
    "        if (len(parts) > 2):\n",
    "            index_to_remove = len(parts) - 2\n",
    "            \n",
    "            # remove aggregation function\n",
    "            if (parts[index_to_remove] in ['min', 'std', 'max', 'mea', 'td']):\n",
    "                parts.remove(parts[index_to_remove])\n",
    "                \n",
    "            result = '_'.join(parts)\n",
    "            return result\n",
    "        else:\n",
    "            return str_to_check    \n",
    "\n",
    "        \n",
    "    def get_heatmap_matrix(corr_matrix:DataFrame):\n",
    "        heatmap_matrix = pd.DataFrame(corr_matrix['target'].abs())\n",
    "        heatmap_matrix = heatmap_matrix.sort_values(by='target', ascending=False)\n",
    "        heatmap_matrix = heatmap_matrix.drop(index=['target'])           \n",
    "        return heatmap_matrix\n",
    "    \n",
    "    # index - column name\n",
    "    # target - value\n",
    "    def plot_heatmap(heatmap_matrix:DataFrame):\n",
    "        plt.figure(figsize=(40, 120))\n",
    "        heatmap = sns.heatmap(heatmap_matrix, vmin=-1, vmax=1, annot=True, cmap='BrBG')\n",
    "        heatmap.set_title('Features Correlating with Churn Rate', fontdict={'fontsize':18}, pad=16);\n",
    "        return heatmap_matrix\n",
    "    \n",
    "    def get_important_features(heatmap_matrix:DataFrame, use_groupping = False, num_of_features:int = -1):\n",
    "        df_features = heatmap_matrix.reset_index()\n",
    "        df_features = df_features.rename(columns = {'index':'feature'})\n",
    "        \n",
    "        # apply aggregation function for further groupping\n",
    "        df_features['feature_group'] = df_features['feature'].apply(FeatureHelper.remove_aggr_function)\n",
    "        df_features = df_features[['feature', 'feature_group', 'target']]\n",
    "        sorted_features = df_features.sort_values(by=['feature_group', 'target'], ascending = [False, False])\n",
    "        \n",
    "        # take first item from the group\n",
    "        if (use_groupping == True):\n",
    "            important_features = sorted_features.groupby('feature_group').first()\n",
    "        else:\n",
    "            important_features = sorted_features\n",
    "\n",
    "        # order by target\n",
    "        important_features = important_features.sort_values(by='target', ascending=False)\n",
    "           \n",
    "        # take N first rows\n",
    "        if (num_of_features != -1):\n",
    "            important_features = important_features.head(num_of_features)\n",
    "        \n",
    "        # optimize for heatmap\n",
    "        important_features = important_features.reset_index()\n",
    "        important_features = important_features[['feature', 'target']]\n",
    "        important_features.index = important_features['feature']\n",
    "        important_features.index.name = None\n",
    "        important_features = important_features[['target']]\n",
    "        important_features = important_features[important_features['target'] > 0]\n",
    "        \n",
    "        return important_features\n",
    "    \n",
    "    def get_important_features_tuples(heatmap_matrix:DataFrame, num_of_features:int = -1):\n",
    "        important_features = FeatureHelper.get_important_features(heatmap_matrix, num_of_features)\n",
    "        \n",
    "        if (num_of_features == -1):\n",
    "            num_of_features = len(important_features)\n",
    "        \n",
    "        important_features_tuples = list(zip(important_features.index, \n",
    "                                             important_features.target, \n",
    "                                             list(range(0, num_of_features))))\n",
    "        \n",
    "        return important_features_tuples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "b170f8eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "class FeatureSelector(abc.ABC):\n",
    "\n",
    "    @abc.abstractmethod\n",
    "    def get_heatmap(self) -> pd.DataFrame:\n",
    "        pass\n",
    "    \n",
    "    @abc.abstractmethod\n",
    "    def plot_heatmap(self):\n",
    "        pass\n",
    "\n",
    "    @abc.abstractmethod\n",
    "    def get_important_features(self) -> pd.DataFrame:\n",
    "        pass\n",
    "    \n",
    "    @abc.abstractmethod\n",
    "    # 1 - feature name, 2 - target, 3 - sorted number\n",
    "    def get_important_features_tuples(self) -> List[tuple[str, float, int]]:\n",
    "        pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "afe1177f",
   "metadata": {},
   "outputs": [],
   "source": [
    "class CorrelationSelector(FeatureSelector):\n",
    "    \n",
    "    def __init__(self, data:pd.DataFrame, corr_method:str, num_of_features:int):\n",
    "        self.data = data\n",
    "        self.corr_method = corr_method\n",
    "        self.file_prefix = corr_method\n",
    "        self.num_of_features = num_of_features\n",
    "    \n",
    "    def get_heatmap(self) -> pd.DataFrame:\n",
    "        self.save_path = f'{self.file_prefix}_{_СORRELATION_MATRIX_PATH_}'\n",
    "        self.corr_m = FeatureHelper.get_correlation_matrix(self.data, self.corr_method, self.save_path)\n",
    "        self.heatmap_m = FeatureHelper.get_heatmap_matrix(self.corr_m)\n",
    "        return self.heatmap_m \n",
    "    \n",
    "    def get_important_features(self) -> pd.DataFrame:\n",
    "        return FeatureHelper.get_important_features(self.heatmap_m, self.num_of_features)\n",
    "    \n",
    "    def plot_heatmap(self):\n",
    "        FeatureHelper.plot_heatmap(self.get_important_features())\n",
    "    \n",
    "    def get_non_correlated_features(self, barrier_coef:float, do_log:bool) -> List[str]:\n",
    "        \n",
    "        important_tuples = FeatureHelper.get_important_features_tuples(self.heatmap_m, self.num_of_features)\n",
    "        # f1, f2, corr\n",
    "        features_corr = FeatureHelper.get_feature_correlation_df(self.corr_m)\n",
    "        \n",
    "        already_processed = set()\n",
    "        all_features = [t[0] for t in important_tuples]\n",
    "\n",
    "        for f in all_features:\n",
    "            # get correlated features\n",
    "            correlated = list(features_corr[(features_corr['f1']==f) & (features_corr['corr'] > barrier_coef)]['f2'])\n",
    "\n",
    "            # if highly correlated features exist\n",
    "            if (len(correlated)>0):\n",
    "\n",
    "                for to_remove in correlated:\n",
    "                    if (to_remove not in already_processed):\n",
    "                        if (to_remove in all_features):\n",
    "                            all_features.remove(to_remove)\n",
    "                            if do_log: print(f'Removing: {to_remove} for {f}')            \n",
    "\n",
    "        # remember initial feature\n",
    "        already_processed.add(f)\n",
    "        \n",
    "        # return non-correlated features\n",
    "        return all_features\n",
    "    \n",
    "    def get_important_noncorrelated_features_tuples(self, mutual_correlation_filter:float, feature_importance_filter:float):\n",
    "        \n",
    "        final = []\n",
    "        important = self.get_important_features_tuples()\n",
    "        non_correlated = self.get_non_correlated_features(mutual_correlation_filter, False)\n",
    "        \n",
    "        for i in important:\n",
    "            if (i[0] in non_correlated and i[1] > feature_importance_filter):\n",
    "                final.append(i)\n",
    "\n",
    "        return final\n",
    "                        \n",
    "    def get_important_features_tuples(self) ->  List[tuple[str, float, int]]:\n",
    "        return FeatureHelper.get_important_features_tuples(self.heatmap_m, self.num_of_features)\n",
    "    \n",
    "    def __str__(self):\n",
    "        return type(self).__name__ + '_' + self.corr_method"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "01bd308f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# https://nitin9809.medium.com/lightgbm-binary-classification-multi-class-classification-regression-using-python-4f22032b36a2\n",
    "# https://www.analyticsvidhya.com/blog/2020/10/feature-selection-techniques-in-machine-learning/\n",
    "class LGBMSelector(FeatureSelector):\n",
    "    \n",
    "    def __init__(self, data:pd.DataFrame, num_of_features:int):\n",
    "        self.data = data\n",
    "        self.num_of_features = num_of_features\n",
    "        self.train_model()\n",
    "    \n",
    "    def train_model(self):\n",
    "        test, train = split_test_train(self.data)\n",
    "\n",
    "        self.y_train = train['target'].round(0).astype(int)\n",
    "        self.y_test = test['target'].round(0).astype(int)\n",
    "\n",
    "        train = train.drop(['target'], axis=1)\n",
    "        test = test.drop(['target'], axis=1)\n",
    "\n",
    "        # save regressor\n",
    "        self.regressor = lg.LGBMClassifier()\n",
    "        self.regressor.fit(train, self.y_train)\n",
    "        predicted = self.regressor.predict(test)\n",
    "        \n",
    "        # save predicted data\n",
    "        self.predicted = predicted.round(0).astype(int)\n",
    "    \n",
    "    def get_heatmap(self) -> pd.DataFrame:\n",
    "        df_feature_importance = pd.DataFrame(list(zip(list(self.regressor.feature_importances_), list(self.data.columns))))\n",
    "        df_feature_importance = df_feature_importance.set_axis(['target', 'feature'], axis=1)\n",
    "        df_feature_importance = df_feature_importance.sort_values(by=['target'], ascending=False)\n",
    "        df_feature_importance = df_feature_importance.set_index('feature')\n",
    "        df_feature_importance.index.name = None\n",
    "        self.heatmap_m = df_feature_importance\n",
    "        return self.heatmap_m\n",
    "    \n",
    "    def plot_heatmap(self):\n",
    "        FeatureHelper.plot_heatmap(self.get_important_features())\n",
    "\n",
    "    def get_important_features(self) -> pd.DataFrame:\n",
    "        return FeatureHelper.get_important_features(self.heatmap_m, self.num_of_features)\n",
    "    \n",
    "    def get_important_features_tuples(self) -> List[tuple[str, float, int]]:\n",
    "        features_tuples = FeatureHelper.get_important_features_tuples(self.heatmap_m, self.num_of_features)\n",
    "        return features_tuples\n",
    "        \n",
    "    def get_ROCAUC(self):\n",
    "        return roc_auc_score(self.y_test, self.predicted)\n",
    "    \n",
    "    def get_ROCAUC_2(self):\n",
    "        return roc_auc_score(self.predicted, self.y_test)\n",
    "    \n",
    "    def get_MSE(self):\n",
    "        return mean_squared_error(self.predicted, self.y_test)\n",
    "    \n",
    "    def get_confusion_matrix(self):\n",
    "        return confusion_matrix(self.y_test, self.predicted)\n",
    "    \n",
    "    def __str__(self):\n",
    "        return type(self).__name__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "6fc80a6b",
   "metadata": {},
   "outputs": [],
   "source": [
    "class TransformPipe:\n",
    "    \n",
    "    def __init__(self, funcs, **kwargs):\n",
    "        self.funcs = funcs\n",
    "        self.kwargs = kwargs\n",
    "    \n",
    "    def transform(self, df:DataFrame) -> DataFrame:\n",
    "        for f in self.funcs:\n",
    "            df = f(df, **self.kwargs)\n",
    "            \n",
    "        return df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "688eb39d",
   "metadata": {},
   "source": [
    "## Load Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "87d3baf5",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df, train_num, train_dpi, test_df, test_num, test_dpi = load_churn_reduced()\n",
    "df_combine, df_combine_num, df_combine_dpi = combine_data(train_df, train_num, train_dpi, test_df, test_num, test_dpi)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "36f98699",
   "metadata": {},
   "source": [
    "### Feature importance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "a3216c6b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# https://towardsdatascience.com/deep-dive-on-ml-techniques-for-feature-selection-in-python-part-2-c258f8a2ac43\n",
    "# https://www.kaggle.com/code/gomes555/tps-jun2021-feature-selection-lightgbm-tuner\n",
    "\n",
    "result = {}\n",
    "seleсtors = [ CorrelationSelector(df_combine, 'pearson', -1),\n",
    "              CorrelationSelector(df_combine, 'spearman', -1),\n",
    "              LGBMSelector(df_combine, _MAX_FEATURES_) ]\n",
    "\n",
    "for selector in seleсtors:\n",
    "    heatmap = selector.get_heatmap()\n",
    "    features = selector.get_important_features()\n",
    "    features_tuples = selector.get_important_features_tuples()\n",
    "    result[selector.__str__()] = selector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "23b74423",
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "CorrelationSelector.get_important_noncorrelated_features_tuples() takes 2 positional arguments but 3 were given",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[22], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m df_non_corr \u001b[38;5;241m=\u001b[39m \u001b[43mresult\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mCorrelationSelector_spearman\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_important_noncorrelated_features_tuples\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m0.95\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m0.05\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "\u001b[1;31mTypeError\u001b[0m: CorrelationSelector.get_important_noncorrelated_features_tuples() takes 2 positional arguments but 3 were given"
     ]
    }
   ],
   "source": [
    "df_non_corr = result['CorrelationSelector_spearman'].get_important_noncorrelated_features_tuples(0.95, 0.05)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bcb03072",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8ef74ead",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a83f6e4d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4a0b9bce",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "18278083",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "254b5c0b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c4d2872d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "811cb198",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "488ca55e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c7bbd2ad",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d25fd7fa",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bab80c2e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1d588c52",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b4b83706",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a3dcb6c9",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "24b131c5",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1a488a5c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3bdf3754",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fc347cba",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ea5333d1",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "25b4609e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b23e7933",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0d8e7c95",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "acce2686",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "12cf1e8a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "00ad5c07",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d296e9f1",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "41cc09d4",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1d0fcf1c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "93198251",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1aaca571",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a7d812fc",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ff1d902a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "91eaf288",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d264c63f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e648b504",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e23b84c8",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3f234123",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a466daac",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "35672894",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2f9c4723",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5e6208ce",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "63156c72",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c9d62c18",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "63e12f2f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "deed22b0",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "66bdb310",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d1bc3af8",
   "metadata": {},
   "outputs": [],
   "source": [
    "existing = ['target', 'ind']\n",
    "roc_auc = -1\n",
    "prev_roc_auc = -1\n",
    "increase_rate = -1\n",
    "\n",
    "for c in list(df_combine.columns):\n",
    "    if c != 'target':\n",
    "        \n",
    "        # add column\n",
    "        existing.append(c)\n",
    "        \n",
    "        # new dataset\n",
    "        df = df_combine[existing]\n",
    "        \n",
    "        # build model\n",
    "        test, train = split_test_train(df)\n",
    "        y_train = train['target']\n",
    "        y_test = test['target']\n",
    "        train = train.drop(['target'], axis=1)\n",
    "        test = test.drop(['target'], axis=1)\n",
    "        regressor = lg.LGBMClassifier()\n",
    "        regressor.fit(train, y_train)\n",
    "        \n",
    "        # calculate metric\n",
    "        predicted = regressor.predict(test)\n",
    "        \n",
    "        try:\n",
    "            roc_auc = roc_auc_score(predicted, y_test)\n",
    "        except ValueError:\n",
    "            roc_auc = -1\n",
    "        \n",
    "        print(f'{len(existing)} -> {roc_auc}')\n",
    "        \n",
    "        # remove current column\n",
    "        # existing "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8a6f6827",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f8147b6c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c707d46b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e6521efa",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6dfe3223",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b7f5c3ab",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a00e3b47",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "541839ca",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4191b5c8",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "564cb72a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ff7b6afc",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "94f8cfc5",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "06063fa2",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "542ed9ff",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5bf77688",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0596201f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f5ca1e80",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5c480b43",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "c4ab493d",
   "metadata": {},
   "source": [
    "### Check if dataset is balanced"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7c07cc69",
   "metadata": {},
   "outputs": [],
   "source": [
    "churned = len(df_combine[df_combine['target'] == 1])\n",
    "not_churned = len(df_combine[df_combine['target'] == 0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "128a1f77",
   "metadata": {},
   "outputs": [],
   "source": [
    "y = [churned, not_churned]\n",
    "x = ['Churned', 'Not churned']\n",
    "plt.bar(x,y)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fbdd1142",
   "metadata": {},
   "source": [
    "## Feature engineering\n",
    "#### Check inbound calls from non-vodaphone number\n",
    "#### Check outbound calls to non-vodaphone number\n",
    "#### SMS from non-vodaphone number\n",
    "#### SMS to non-vodaphone number"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "47767b50",
   "metadata": {},
   "source": [
    "## Correlation matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a4c23854",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7b386d20",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c366986a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e7a8b4ca",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "7ee8d68b",
   "metadata": {},
   "source": [
    "## Explore numbers abonent had communication with + frequency"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f46ce76b",
   "metadata": {},
   "outputs": [],
   "source": [
    "churned = df_combine[df_combine['target'] == 1]\n",
    "churned_with_nums = pd.merge(churned, df_combine_num, on='abon_id', how='left')\n",
    "churned_numbers = list(churned_with_nums['bnum'].unique())\n",
    "\n",
    "non_churned = df_combine[df_combine['target'] == 0]\n",
    "non_churned_with_nums = pd.merge(non_churned, df_combine_num, on='abon_id', how='left')\n",
    "non_churned_numbers = list(non_churned_with_nums['bnum'].unique())\n",
    "\n",
    "number_abon_had_communicated = (set(churned_numbers) - set(non_churned_numbers))\n",
    "df_number_abon_had_communicated = pd.DataFrame(number_abon_had_communicated, columns= ['bnum'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "95fddd12",
   "metadata": {},
   "outputs": [],
   "source": [
    "churned_with_nums[churned_with_nums['bnum'].isin(list(number_abon_had_communicated))]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "61e2d077",
   "metadata": {},
   "source": [
    "## Telephone Feature"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "179f3d3d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "75958788",
   "metadata": {},
   "source": [
    "## Groupping"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5531cec4",
   "metadata": {},
   "outputs": [],
   "source": [
    "gr = train_num.groupby(['abon_id'])\n",
    "gr.groups"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e6992251",
   "metadata": {},
   "outputs": [],
   "source": [
    "# cor_matrix = train_df.corr()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8f62c2db",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "96ca83cb",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "94c6700b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ef537d9a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b8d1015c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "facebe50",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ad075db8",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3c644d06",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e22e959b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bbc5e657",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aa9765e5",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3d167d1d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cf809d80",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1f0e5976",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7cfbbe71",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d3ce6f7b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c9276c26",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
